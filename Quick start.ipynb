{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8590b196",
   "metadata": {},
   "source": [
    "### Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dd8b7",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d39981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe15a93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 17:44:54,027\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "2022-10-17 17:45:09,248\tWARNING read_api.py:291 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n",
      "Map_Batches: 100%|████████████████████████████████| 1/1 [00:00<00:00,  6.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n",
    "\n",
    "# Split data into train and validation\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# Create a test dataset by dropping the target column\n",
    "test_dataset = valid_dataset.drop_columns(cols=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17747792",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b25848",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 22:43:34,371\tINFO tensorboardx.py:170 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2022-10-16 22:43:34,373\tWARNING callback.py:108 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-10-16 22:43:53 (running for 00:00:19.53)<br>Memory usage on this node: 9.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/5.14 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/yjkim/ray_results/XGBoostTrainer_2022-10-16_22-43-34<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_87799_00000</td><td>TERMINATED</td><td>127.0.0.1:42146</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         15.3273</td><td style=\"text-align: right;\">      0.0179314</td><td style=\"text-align: right;\">            0</td><td style=\"text-align: right;\">      0.0879959</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=42173)\u001b[0m [22:43:50] task [xgboost.ray]:140413578906544 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=42175)\u001b[0m [22:43:50] task [xgboost.ray]:140233097997328 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=42191)\u001b[0m [22:43:50] task [xgboost.ray]:140477513718752 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=42192)\u001b[0m [22:43:50] task [xgboost.ray]:140655252605824 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for XGBoostTrainer_87799_00000:\n",
      "  date: 2022-10-16_22-43-53\n",
      "  done: false\n",
      "  experiment_id: b3191d18ca96442990797af779089a50\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 42146\n",
      "  time_since_restore: 14.711936950683594\n",
      "  time_this_iter_s: 14.711936950683594\n",
      "  time_total_s: 14.711936950683594\n",
      "  timestamp: 1665927833\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.02512562814070352\n",
      "  train-logloss: 0.46656074401122244\n",
      "  training_iteration: 1\n",
      "  trial_id: '87799_00000'\n",
      "  valid-error: 0.11695906432748537\n",
      "  valid-logloss: 0.502969495385711\n",
      "  warmup_time: 0.005882978439331055\n",
      "  \n",
      "Result for XGBoostTrainer_87799_00000:\n",
      "  date: 2022-10-16_22-43-53\n",
      "  done: true\n",
      "  experiment_id: b3191d18ca96442990797af779089a50\n",
      "  experiment_tag: '0'\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 42146\n",
      "  time_since_restore: 15.327291011810303\n",
      "  time_this_iter_s: 0.47252488136291504\n",
      "  time_total_s: 15.327291011810303\n",
      "  timestamp: 1665927833\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.0\n",
      "  train-logloss: 0.01793136571220417\n",
      "  training_iteration: 21\n",
      "  trial_id: '87799_00000'\n",
      "  valid-error: 0.04093567251461988\n",
      "  valid-logloss: 0.0879958809778225\n",
      "  warmup_time: 0.005882978439331055\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 22:43:54,021\tINFO tune.py:758 -- Total run time: 19.66 seconds (19.52 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train-logloss': 0.01793136571220417, 'train-error': 0.0, 'valid-logloss': 0.0879958809778225, 'valid-error': 0.04093567251461988, 'time_this_iter_s': 0.47252488136291504, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 21, 'trial_id': '87799_00000', 'experiment_id': 'b3191d18ca96442990797af779089a50', 'date': '2022-10-16_22-43-53', 'timestamp': 1665927833, 'time_total_s': 15.327291011810303, 'pid': 42146, 'hostname': 'YONGJINs-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 15.327291011810303, 'timesteps_since_restore': 0, 'iterations_since_restore': 21, 'warmup_time': 0.005882978439331055, 'experiment_tag': '0'}\n"
     ]
    }
   ],
   "source": [
    "from ray.data.preprocessors import StandardScaler\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "\n",
    "# Preprocessing\n",
    "preprocessor = StandardScaler(columns=[\"mean radius\", \"mean texture\"])\n",
    "\n",
    "# Training\n",
    "trainer = XGBoostTrainer(\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=4,    # number of workers to use for data parallelism\n",
    "        use_gpu=False,    # Whether to use GPU accleration\n",
    "    ),\n",
    "    label_column='target',\n",
    "    num_boost_round=20,\n",
    "    params={\n",
    "        'objective': 'binary:logistic',    # XGBoost specific params\n",
    "        'eval_metric': ['logloss', 'error']    # \"tree_method\": \"gpu_hist\"\n",
    "    },\n",
    "    datasets={'train': train_dataset, 'valid': valid_dataset},\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "\n",
    "result = trainer.fit()\n",
    "print(result.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbca532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "from ray.air.config import RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59cbe767",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 22:48:04,159\tWARNING callback.py:108 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-10-16 22:49:32 (running for 00:01:28.74)<br>Memory usage on this node: 4.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/5.14 GiB heap, 0.0/2.0 GiB objects<br>Current best trial: 28481_00001 with train-logloss=0.01859253883974898 and parameters={'params': {'max_depth': 5}}<br>Result logdir: /Users/yjkim/ray_results/XGBoostTrainer_2022-10-16_22-48-04<br>Number of trials: 5/5 (5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  params/max_depth</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th><th style=\"text-align: right;\">  valid-logloss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoostTrainer_28481_00000</td><td>TERMINATED</td><td>127.0.0.1:43130</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         12.3457</td><td style=\"text-align: right;\">      0.0410722</td><td style=\"text-align: right;\">   0.00502513</td><td style=\"text-align: right;\">      0.1029   </td></tr>\n",
       "<tr><td>XGBoostTrainer_28481_00001</td><td>TERMINATED</td><td>127.0.0.1:43203</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         13.6486</td><td style=\"text-align: right;\">      0.0185925</td><td style=\"text-align: right;\">   0         </td><td style=\"text-align: right;\">      0.0818791</td></tr>\n",
       "<tr><td>XGBoostTrainer_28481_00002</td><td>TERMINATED</td><td>127.0.0.1:43261</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         13.8138</td><td style=\"text-align: right;\">      0.0954546</td><td style=\"text-align: right;\">   0.0201005 </td><td style=\"text-align: right;\">      0.11149  </td></tr>\n",
       "<tr><td>XGBoostTrainer_28481_00003</td><td>TERMINATED</td><td>127.0.0.1:43319</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         13.8127</td><td style=\"text-align: right;\">      0.0185925</td><td style=\"text-align: right;\">   0         </td><td style=\"text-align: right;\">      0.0818791</td></tr>\n",
       "<tr><td>XGBoostTrainer_28481_00004</td><td>TERMINATED</td><td>127.0.0.1:43385</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         13.7265</td><td style=\"text-align: right;\">      0.0410722</td><td style=\"text-align: right;\">   0.00502513</td><td style=\"text-align: right;\">      0.1029   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43161)\u001b[0m [22:48:18] task [xgboost.ray]:140566358526800 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43158)\u001b[0m [22:48:18] task [xgboost.ray]:140395063147392 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43175)\u001b[0m [22:48:18] task [xgboost.ray]:140267852003840 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43176)\u001b[0m [22:48:18] task [xgboost.ray]:140621523053296 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for XGBoostTrainer_28481_00000:\n",
      "  date: 2022-10-16_22-48-19\n",
      "  done: false\n",
      "  experiment_id: e6f83f23135245dabe3aec23525d5504\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43130\n",
      "  time_since_restore: 11.232172966003418\n",
      "  time_this_iter_s: 11.232172966003418\n",
      "  time_total_s: 11.232172966003418\n",
      "  timestamp: 1665928099\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.04522613065326633\n",
      "  train-logloss: 0.48458515279856157\n",
      "  training_iteration: 1\n",
      "  trial_id: '28481_00000'\n",
      "  valid-error: 0.1111111111111111\n",
      "  valid-logloss: 0.5170963152110228\n",
      "  warmup_time: 0.005660057067871094\n",
      "  \n",
      "Result for XGBoostTrainer_28481_00000:\n",
      "  date: 2022-10-16_22-48-20\n",
      "  done: true\n",
      "  experiment_id: e6f83f23135245dabe3aec23525d5504\n",
      "  experiment_tag: 0_max_depth=2\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43130\n",
      "  time_since_restore: 12.345662832260132\n",
      "  time_this_iter_s: 0.6764390468597412\n",
      "  time_total_s: 12.345662832260132\n",
      "  timestamp: 1665928100\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.0050251256281407\n",
      "  train-logloss: 0.04107216576900539\n",
      "  training_iteration: 21\n",
      "  trial_id: '28481_00000'\n",
      "  valid-error: 0.04093567251461988\n",
      "  valid-logloss: 0.10290026689923167\n",
      "  warmup_time: 0.005660057067871094\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43220)\u001b[0m [22:48:35] task [xgboost.ray]:140322445052944 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43221)\u001b[0m [22:48:35] task [xgboost.ray]:140210994023152 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43243)\u001b[0m [22:48:35] task [xgboost.ray]:140330614512752 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43242)\u001b[0m [22:48:35] task [xgboost.ray]:140679429614608 got new rank 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for XGBoostTrainer_28481_00001:\n",
      "  date: 2022-10-16_22-48-38\n",
      "  done: false\n",
      "  experiment_id: 57cf745d94c74c46b038d67712bc9447\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43203\n",
      "  time_since_restore: 13.186815977096558\n",
      "  time_this_iter_s: 13.186815977096558\n",
      "  time_total_s: 13.186815977096558\n",
      "  timestamp: 1665928118\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.02512562814070352\n",
      "  train-logloss: 0.4670509481849383\n",
      "  training_iteration: 1\n",
      "  trial_id: '28481_00001'\n",
      "  valid-error: 0.09941520467836257\n",
      "  valid-logloss: 0.501814771813956\n",
      "  warmup_time: 0.005167961120605469\n",
      "  \n",
      "Result for XGBoostTrainer_28481_00001:\n",
      "  date: 2022-10-16_22-48-38\n",
      "  done: true\n",
      "  experiment_id: 57cf745d94c74c46b038d67712bc9447\n",
      "  experiment_tag: 1_max_depth=5\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43203\n",
      "  time_since_restore: 13.648637771606445\n",
      "  time_this_iter_s: 0.3365809917449951\n",
      "  time_total_s: 13.648637771606445\n",
      "  timestamp: 1665928118\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.0\n",
      "  train-logloss: 0.01859253883974898\n",
      "  training_iteration: 21\n",
      "  trial_id: '28481_00001'\n",
      "  valid-error: 0.02339181286549707\n",
      "  valid-logloss: 0.08187905736866663\n",
      "  warmup_time: 0.005167961120605469\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43284)\u001b[0m [22:48:53] task [xgboost.ray]:140684538276928 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43287)\u001b[0m [22:48:53] task [xgboost.ray]:140284058790976 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43301)\u001b[0m [22:48:53] task [xgboost.ray]:140628074556336 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43300)\u001b[0m [22:48:53] task [xgboost.ray]:140225933077472 got new rank 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for XGBoostTrainer_28481_00002:\n",
      "  date: 2022-10-16_22-48-56\n",
      "  done: false\n",
      "  experiment_id: 29351ec5345f45098ea25071783863ef\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43261\n",
      "  time_since_restore: 13.28571605682373\n",
      "  time_this_iter_s: 13.28571605682373\n",
      "  time_total_s: 13.28571605682373\n",
      "  timestamp: 1665928136\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.07537688442211055\n",
      "  train-logloss: 0.5116842961940334\n",
      "  training_iteration: 1\n",
      "  trial_id: '28481_00002'\n",
      "  valid-error: 0.10526315789473684\n",
      "  valid-logloss: 0.5233400317660549\n",
      "  warmup_time: 0.0054357051849365234\n",
      "  \n",
      "Result for XGBoostTrainer_28481_00002:\n",
      "  date: 2022-10-16_22-48-57\n",
      "  done: true\n",
      "  experiment_id: 29351ec5345f45098ea25071783863ef\n",
      "  experiment_tag: 2_max_depth=1\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43261\n",
      "  time_since_restore: 13.813767910003662\n",
      "  time_this_iter_s: 0.39649200439453125\n",
      "  time_total_s: 13.813767910003662\n",
      "  timestamp: 1665928137\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.02010050251256281\n",
      "  train-logloss: 0.09545462628143217\n",
      "  training_iteration: 21\n",
      "  trial_id: '28481_00002'\n",
      "  valid-error: 0.02923976608187134\n",
      "  valid-logloss: 0.1114896584944854\n",
      "  warmup_time: 0.0054357051849365234\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43345)\u001b[0m [22:49:11] task [xgboost.ray]:140218745084944 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43342)\u001b[0m [22:49:11] task [xgboost.ray]:140289721101280 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43359)\u001b[0m [22:49:11] task [xgboost.ray]:140614812167088 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43358)\u001b[0m [22:49:11] task [xgboost.ray]:140268613274496 got new rank 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for XGBoostTrainer_28481_00003:\n",
      "  date: 2022-10-16_22-49-14\n",
      "  done: false\n",
      "  experiment_id: bef307c5a147406f81a2e9f0fc2dee87\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43319\n",
      "  time_since_restore: 13.43497610092163\n",
      "  time_this_iter_s: 13.43497610092163\n",
      "  time_total_s: 13.43497610092163\n",
      "  timestamp: 1665928154\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.02512562814070352\n",
      "  train-logloss: 0.4670509481849383\n",
      "  training_iteration: 1\n",
      "  trial_id: '28481_00003'\n",
      "  valid-error: 0.09941520467836257\n",
      "  valid-logloss: 0.501814771813956\n",
      "  warmup_time: 0.005287885665893555\n",
      "  \n",
      "Result for XGBoostTrainer_28481_00003:\n",
      "  date: 2022-10-16_22-49-15\n",
      "  done: true\n",
      "  experiment_id: bef307c5a147406f81a2e9f0fc2dee87\n",
      "  experiment_tag: 3_max_depth=5\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43319\n",
      "  time_since_restore: 13.81273603439331\n",
      "  time_this_iter_s: 0.2525599002838135\n",
      "  time_total_s: 13.81273603439331\n",
      "  timestamp: 1665928155\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.0\n",
      "  train-logloss: 0.01859253883974898\n",
      "  training_iteration: 21\n",
      "  trial_id: '28481_00003'\n",
      "  valid-error: 0.02339181286549707\n",
      "  valid-logloss: 0.08187905736866663\n",
      "  warmup_time: 0.005287885665893555\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43402)\u001b[0m [22:49:29] task [xgboost.ray]:140162951408560 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43401)\u001b[0m [22:49:29] task [xgboost.ray]:140440858651568 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43416)\u001b[0m [22:49:29] task [xgboost.ray]:140216202292240 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=43417)\u001b[0m [22:49:29] task [xgboost.ray]:140379561003712 got new rank 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for XGBoostTrainer_28481_00004:\n",
      "  date: 2022-10-16_22-49-32\n",
      "  done: false\n",
      "  experiment_id: cc725e3c8ab04d1a9c2cdede03203dbd\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43385\n",
      "  time_since_restore: 13.363611936569214\n",
      "  time_this_iter_s: 13.363611936569214\n",
      "  time_total_s: 13.363611936569214\n",
      "  timestamp: 1665928172\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.04522613065326633\n",
      "  train-logloss: 0.48458515279856157\n",
      "  training_iteration: 1\n",
      "  trial_id: '28481_00004'\n",
      "  valid-error: 0.1111111111111111\n",
      "  valid-logloss: 0.5170963152110228\n",
      "  warmup_time: 0.005262136459350586\n",
      "  \n",
      "Result for XGBoostTrainer_28481_00004:\n",
      "  date: 2022-10-16_22-49-32\n",
      "  done: true\n",
      "  experiment_id: cc725e3c8ab04d1a9c2cdede03203dbd\n",
      "  experiment_tag: 4_max_depth=2\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 43385\n",
      "  time_since_restore: 13.726532936096191\n",
      "  time_this_iter_s: 0.23717474937438965\n",
      "  time_total_s: 13.726532936096191\n",
      "  timestamp: 1665928172\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.0050251256281407\n",
      "  train-logloss: 0.04107216576900539\n",
      "  training_iteration: 21\n",
      "  trial_id: '28481_00004'\n",
      "  valid-error: 0.04093567251461988\n",
      "  valid-logloss: 0.10290026689923167\n",
      "  warmup_time: 0.005262136459350586\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-16 22:49:33,020\tINFO tune.py:758 -- Total run time: 88.87 seconds (88.73 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Result: Result(metrics={'train-logloss': 0.01859253883974898, 'train-error': 0.0, 'valid-logloss': 0.08187905736866663, 'valid-error': 0.02339181286549707, 'done': True, 'trial_id': '28481_00001', 'experiment_tag': '1_max_depth=5'}, error=None, log_dir=PosixPath('/Users/yjkim/ray_results/XGBoostTrainer_2022-10-16_22-48-04/XGBoostTrainer_28481_00001_1_max_depth=5_2022-10-16_22-48-22'))\n"
     ]
    }
   ],
   "source": [
    "# Hyperparmeter Tuning\n",
    "param_space = {'params': {'max_depth': tune.randint(1, 9)}}\n",
    "metric = 'train-logloss'\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(num_samples=5, metric=metric, mode='min')\n",
    ")\n",
    "\n",
    "# Excute tuning\n",
    "result_grid = tuner.fit()\n",
    "\n",
    "# Fetch the best result\n",
    "best_result = result_grid.get_best_result()\n",
    "print(f\"Best Result: {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0b509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.xgboost import XGBoostPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7bfa1f0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map Progress (1 actors 1 pending): 100%|███████████████████████| 1/1 [00:02<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': 0.9967517852783203}\n",
      "{'predictions': 0.9956080317497253}\n",
      "{'predictions': 0.0035305859055370092}\n",
      "{'predictions': 0.9967517852783203}\n",
      "{'predictions': 0.9968827962875366}\n",
      "{'predictions': 0.9960047602653503}\n",
      "{'predictions': 0.9917015433311462}\n",
      "{'predictions': 0.995203971862793}\n",
      "{'predictions': 0.27522677183151245}\n",
      "{'predictions': 0.9821683764457703}\n",
      "{'predictions': 0.0035305859055370092}\n",
      "{'predictions': 0.9960752129554749}\n",
      "{'predictions': 0.9656598567962646}\n",
      "{'predictions': 0.9889512658119202}\n",
      "{'predictions': 0.9943472743034363}\n",
      "{'predictions': 0.26353344321250916}\n",
      "{'predictions': 0.4275687336921692}\n",
      "{'predictions': 0.9949140548706055}\n",
      "{'predictions': 0.9823238849639893}\n",
      "{'predictions': 0.0035305859055370092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Batch Inference\n",
    "\n",
    "# also create a checkpoint from a trained model using `XGBoostCheckpoint.from_model`\n",
    "checkpoint = best_result.checkpoint\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(checkpoint, XGBoostPredictor)\n",
    "\n",
    "predicted_probabilities = batch_predictor.predict(test_dataset)\n",
    "predicted_probabilities.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7b243",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1059f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "\n",
    "from ray import train\n",
    "from ray.air import session\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02b75c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Create a preprocessor to scale some columns and concatenate the result\n",
    "preprocessor = Chain(\n",
    "    StandardScaler(columns=['mean radius', 'mean texture']),\n",
    "    Concatenator(exclude=['target'], dtype=np.float32)\n",
    ")\n",
    "\n",
    "# Training\n",
    "def create_model(input_features):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features=input_features, out_features=16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    batch_size = config['batch_size']\n",
    "    lr = config['lr']\n",
    "    epochs = config['num_epochs']\n",
    "    num_features = config['num_features']\n",
    "    \n",
    "    # Get the Ray Dataset shard for this data parallel worker and convert it to a PyTorch Dataset\n",
    "    train_data = train.get_dataset_shard('train')\n",
    "    \n",
    "    # createa model\n",
    "    model = create_model(num_features)\n",
    "    model = train.torch.prepare_model(model)\n",
    "    \n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for cur_epoch in range(epochs):\n",
    "        for batch in train_data.iter_torch_batches(\n",
    "            batch_size=batch_size, dtypes=torch.float32\n",
    "        ):\n",
    "            # \"concat_out\" is the output column of the Concatenator.\n",
    "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs)\n",
    "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        loss = train_loss.item()\n",
    "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8fc38b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 18:06:36,642\tWARNING callback.py:108 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-10-17 18:06:45 (running for 00:00:09.01)<br>Memory usage on this node: 5.6/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/9.38 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/yjkim/ray_results/TorchTrainer_2022-10-17_18-06-36<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _time_this_iter_s</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_00f31_00000</td><td>TERMINATED</td><td>127.0.0.1:19906</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6.00244</td><td style=\"text-align: right;\">0.240533</td><td style=\"text-align: right;\">  1665997605</td><td style=\"text-align: right;\">          0.0765009</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19921)\u001b[0m 2022-10-17 18:06:42,616\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=3]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19921)\u001b[0m 2022-10-17 18:06:43,751\tINFO train_loop_utils.py:300 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19921)\u001b[0m 2022-10-17 18:06:43,751\tINFO train_loop_utils.py:347 -- Wrapping provided model in DDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_00f31_00000:\n",
      "  _time_this_iter_s: 0.2908341884613037\n",
      "  _timestamp: 1665997604\n",
      "  _training_iteration: 1\n",
      "  date: 2022-10-17_18-06-44\n",
      "  done: false\n",
      "  experiment_id: 7eadc91f541a498b980a041a8f421def\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.672611951828003\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 19906\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.489970922470093\n",
      "  time_this_iter_s: 4.489970922470093\n",
      "  time_total_s: 4.489970922470093\n",
      "  timestamp: 1665997604\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 00f31_00000\n",
      "  warmup_time: 0.004698991775512695\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19923)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19923)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19922)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19922)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19921)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=19921)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_00f31_00000:\n",
      "  _time_this_iter_s: 0.07650089263916016\n",
      "  _timestamp: 1665997605\n",
      "  _training_iteration: 20\n",
      "  date: 2022-10-17_18-06-45\n",
      "  done: true\n",
      "  experiment_id: 7eadc91f541a498b980a041a8f421def\n",
      "  experiment_tag: '0'\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.2405332624912262\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 19906\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.002439260482788\n",
      "  time_this_iter_s: 0.07742428779602051\n",
      "  time_total_s: 6.002439260482788\n",
      "  timestamp: 1665997605\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: 00f31_00000\n",
      "  warmup_time: 0.004698991775512695\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 18:06:45,768\tINFO tune.py:758 -- Total run time: 9.14 seconds (9.00 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last result: {'loss': 0.2405332624912262, '_timestamp': 1665997605, '_time_this_iter_s': 0.07650089263916016, '_training_iteration': 20, 'time_this_iter_s': 0.07742428779602051, 'should_checkpoint': True, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 20, 'trial_id': '00f31_00000', 'experiment_id': '7eadc91f541a498b980a041a8f421def', 'date': '2022-10-17_18-06-45', 'timestamp': 1665997605, 'time_total_s': 6.002439260482788, 'pid': 19906, 'hostname': 'YONGJINs-MacBook-Pro.local', 'node_ip': '127.0.0.1', 'config': {}, 'time_since_restore': 6.002439260482788, 'timesteps_since_restore': 0, 'iterations_since_restore': 20, 'warmup_time': 0.004698991775512695, 'experiment_tag': '0'}\n"
     ]
    }
   ],
   "source": [
    "num_features = len(train_dataset.schema().names) - 1\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\n",
    "        \"batch_size\": 128,\n",
    "        \"num_epochs\": 20,\n",
    "        \"num_features\": num_features,\n",
    "        \"lr\": 0.001,\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=3,  # Number of workers to use for data parallelism.\n",
    "        use_gpu=False,\n",
    "        trainer_resources={\"CPU\": 0},  # so that the example works on Colab.\n",
    "    ),\n",
    "    datasets={\"train\": train_dataset},\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "# Execute training.\n",
    "result = trainer.fit()\n",
    "print(f\"Last result: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3eebb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.tuner import Tuner, TuneConfig\n",
    "from ray.air.config import RunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d3bf5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-10-17 18:12:46 (running for 00:00:33.43)<br>Memory usage on this node: 5.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/9.38 GiB heap, 0.0/2.0 GiB objects<br>Current best trial: c9b63_00000 with loss=0.38084739446640015 and parameters={'train_loop_config': {'lr': 0.00017940433949484348}}<br>Result logdir: /Users/yjkim/ray_results/TorchTrainer_2022-10-17_18-12-13<br>Number of trials: 5/5 (5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  train_loop_config/lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _time_this_iter_s</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_c9b63_00000</td><td>TERMINATED</td><td>127.0.0.1:20250</td><td style=\"text-align: right;\">           0.000179404</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5.37057</td><td style=\"text-align: right;\"> 0.380847</td><td style=\"text-align: right;\">  1665997941</td><td style=\"text-align: right;\">          0.092993 </td></tr>\n",
       "<tr><td>TorchTrainer_c9b63_00001</td><td>TERMINATED</td><td>127.0.0.1:20259</td><td style=\"text-align: right;\">           0.000192725</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         8.97167</td><td style=\"text-align: right;\">50       </td><td style=\"text-align: right;\">  1665997948</td><td style=\"text-align: right;\">          0.0842109</td></tr>\n",
       "<tr><td>TorchTrainer_c9b63_00002</td><td>TERMINATED</td><td>127.0.0.1:20292</td><td style=\"text-align: right;\">           0.00346125 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         7.25794</td><td style=\"text-align: right;\"> 0.668383</td><td style=\"text-align: right;\">  1665997954</td><td style=\"text-align: right;\">          0.101945 </td></tr>\n",
       "<tr><td>TorchTrainer_c9b63_00003</td><td>TERMINATED</td><td>127.0.0.1:20310</td><td style=\"text-align: right;\">           0.00576613 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6.9862 </td><td style=\"text-align: right;\"> 0.695373</td><td style=\"text-align: right;\">  1665997960</td><td style=\"text-align: right;\">          0.089077 </td></tr>\n",
       "<tr><td>TorchTrainer_c9b63_00004</td><td>TERMINATED</td><td>127.0.0.1:20319</td><td style=\"text-align: right;\">           0.00473255 </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         8.90445</td><td style=\"text-align: right;\">50       </td><td style=\"text-align: right;\">  1665997966</td><td style=\"text-align: right;\">          0.0826631</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20261)\u001b[0m 2022-10-17 18:12:19,782\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=3]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20261)\u001b[0m 2022-10-17 18:12:19,910\tINFO train_loop_utils.py:300 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20261)\u001b[0m 2022-10-17 18:12:19,910\tINFO train_loop_utils.py:347 -- Wrapping provided model in DDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00000:\n",
      "  _time_this_iter_s: 0.3430471420288086\n",
      "  _timestamp: 1665997940\n",
      "  _training_iteration: 1\n",
      "  date: 2022-10-17_18-12-20\n",
      "  done: false\n",
      "  experiment_id: 88375b47426044188208392f9db1ee8a\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6551185250282288\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20250\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 3.632996082305908\n",
      "  time_this_iter_s: 3.632996082305908\n",
      "  time_total_s: 3.632996082305908\n",
      "  timestamp: 1665997940\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c9b63_00000\n",
      "  warmup_time: 0.005287885665893555\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20263)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20263)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20262)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20262)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20261)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20261)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00000:\n",
      "  _time_this_iter_s: 0.09299302101135254\n",
      "  _timestamp: 1665997941\n",
      "  _training_iteration: 20\n",
      "  date: 2022-10-17_18-12-22\n",
      "  done: true\n",
      "  experiment_id: 88375b47426044188208392f9db1ee8a\n",
      "  experiment_tag: 0_lr=0.0002\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.38084739446640015\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20250\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.370573043823242\n",
      "  time_this_iter_s: 0.08456277847290039\n",
      "  time_total_s: 5.370573043823242\n",
      "  timestamp: 1665997942\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: c9b63_00000\n",
      "  warmup_time: 0.005287885665893555\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20271)\u001b[0m 2022-10-17 18:12:23,500\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=3]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20271)\u001b[0m 2022-10-17 18:12:26,676\tINFO train_loop_utils.py:300 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20271)\u001b[0m 2022-10-17 18:12:26,676\tINFO train_loop_utils.py:347 -- Wrapping provided model in DDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00001:\n",
      "  _time_this_iter_s: 0.3045942783355713\n",
      "  _timestamp: 1665997946\n",
      "  _training_iteration: 1\n",
      "  date: 2022-10-17_18-12-27\n",
      "  done: false\n",
      "  experiment_id: 490fca2ef6b14065af3a73c4634d5c36\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 50.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20259\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.318837881088257\n",
      "  time_this_iter_s: 7.318837881088257\n",
      "  time_total_s: 7.318837881088257\n",
      "  timestamp: 1665997947\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c9b63_00001\n",
      "  warmup_time: 0.0056951045989990234\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20273)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20273)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20271)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20271)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20272)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20272)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00001:\n",
      "  _time_this_iter_s: 0.08421087265014648\n",
      "  _timestamp: 1665997948\n",
      "  _training_iteration: 20\n",
      "  date: 2022-10-17_18-12-28\n",
      "  done: true\n",
      "  experiment_id: 490fca2ef6b14065af3a73c4634d5c36\n",
      "  experiment_tag: 1_lr=0.0002\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 50.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20259\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 8.971671104431152\n",
      "  time_this_iter_s: 0.07729792594909668\n",
      "  time_total_s: 8.971671104431152\n",
      "  timestamp: 1665997948\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: c9b63_00001\n",
      "  warmup_time: 0.0056951045989990234\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20298)\u001b[0m 2022-10-17 18:12:30,831\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=3]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20298)\u001b[0m 2022-10-17 18:12:30,965\tINFO train_loop_utils.py:300 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20298)\u001b[0m 2022-10-17 18:12:30,966\tINFO train_loop_utils.py:347 -- Wrapping provided model in DDP.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20300)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20300)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20298)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20298)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20299)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20299)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00002:\n",
      "  _time_this_iter_s: 0.30349206924438477\n",
      "  _timestamp: 1665997951\n",
      "  _training_iteration: 1\n",
      "  date: 2022-10-17_18-12-31\n",
      "  done: false\n",
      "  experiment_id: 420dbc3d981442cf97d61c6cd5d7e7d6\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 30.769973754882812\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20292\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 4.161451816558838\n",
      "  time_this_iter_s: 4.161451816558838\n",
      "  time_total_s: 4.161451816558838\n",
      "  timestamp: 1665997951\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c9b63_00002\n",
      "  warmup_time: 0.004485130310058594\n",
      "  \n",
      "Result for TorchTrainer_c9b63_00002:\n",
      "  _time_this_iter_s: 0.1019449234008789\n",
      "  _timestamp: 1665997954\n",
      "  _training_iteration: 20\n",
      "  date: 2022-10-17_18-12-34\n",
      "  done: true\n",
      "  experiment_id: 420dbc3d981442cf97d61c6cd5d7e7d6\n",
      "  experiment_tag: 2_lr=0.0035\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.6683834791183472\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20292\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.257944822311401\n",
      "  time_this_iter_s: 0.10204911231994629\n",
      "  time_total_s: 7.257944822311401\n",
      "  timestamp: 1665997954\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: c9b63_00002\n",
      "  warmup_time: 0.004485130310058594\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20313)\u001b[0m 2022-10-17 18:12:37,281\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=3]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20313)\u001b[0m 2022-10-17 18:12:38,425\tINFO train_loop_utils.py:300 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20313)\u001b[0m 2022-10-17 18:12:38,426\tINFO train_loop_utils.py:347 -- Wrapping provided model in DDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00003:\n",
      "  _time_this_iter_s: 0.46407389640808105\n",
      "  _timestamp: 1665997958\n",
      "  _training_iteration: 1\n",
      "  date: 2022-10-17_18-12-38\n",
      "  done: false\n",
      "  experiment_id: 3f68e79a9884401fb72ec2a4e9696302\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.9059874415397644\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20310\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 5.267439126968384\n",
      "  time_this_iter_s: 5.267439126968384\n",
      "  time_total_s: 5.267439126968384\n",
      "  timestamp: 1665997958\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c9b63_00003\n",
      "  warmup_time: 0.004579782485961914\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20314)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20314)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20315)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20315)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20313)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20313)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00003:\n",
      "  _time_this_iter_s: 0.08907699584960938\n",
      "  _timestamp: 1665997960\n",
      "  _training_iteration: 20\n",
      "  date: 2022-10-17_18-12-40\n",
      "  done: true\n",
      "  experiment_id: 3f68e79a9884401fb72ec2a4e9696302\n",
      "  experiment_tag: 3_lr=0.0058\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 0.6953727602958679\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20310\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 6.986196994781494\n",
      "  time_this_iter_s: 0.08703494071960449\n",
      "  time_total_s: 6.986196994781494\n",
      "  timestamp: 1665997960\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: c9b63_00003\n",
      "  warmup_time: 0.004579782485961914\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20325)\u001b[0m 2022-10-17 18:12:41,879\tINFO config.py:71 -- Setting up process group for: env:// [rank=0, world_size=3]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20325)\u001b[0m 2022-10-17 18:12:44,994\tINFO train_loop_utils.py:300 -- Moving model to device: cpu\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20325)\u001b[0m 2022-10-17 18:12:44,995\tINFO train_loop_utils.py:347 -- Wrapping provided model in DDP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00004:\n",
      "  _time_this_iter_s: 0.28025007247924805\n",
      "  _timestamp: 1665997965\n",
      "  _training_iteration: 1\n",
      "  date: 2022-10-17_18-12-45\n",
      "  done: false\n",
      "  experiment_id: c64bf9308ec74c7aa368de807d0b0b0d\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  loss: 50.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20319\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 7.380793809890747\n",
      "  time_this_iter_s: 7.380793809890747\n",
      "  time_total_s: 7.380793809890747\n",
      "  timestamp: 1665997965\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: c9b63_00004\n",
      "  warmup_time: 0.004536867141723633\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20325)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20325)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20327)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20327)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20326)\u001b[0m /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ray/air/_internal/torch_utils.py:122: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=20326)\u001b[0m   return torch.as_tensor(ndarray, dtype=dtype, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for TorchTrainer_c9b63_00004:\n",
      "  _time_this_iter_s: 0.08266305923461914\n",
      "  _timestamp: 1665997966\n",
      "  _training_iteration: 20\n",
      "  date: 2022-10-17_18-12-46\n",
      "  done: true\n",
      "  experiment_id: c64bf9308ec74c7aa368de807d0b0b0d\n",
      "  experiment_tag: 4_lr=0.0047\n",
      "  hostname: YONGJINs-MacBook-Pro.local\n",
      "  iterations_since_restore: 20\n",
      "  loss: 50.0\n",
      "  node_ip: 127.0.0.1\n",
      "  pid: 20319\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 8.904445886611938\n",
      "  time_this_iter_s: 0.07838678359985352\n",
      "  time_total_s: 8.904445886611938\n",
      "  timestamp: 1665997966\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 20\n",
      "  trial_id: c9b63_00004\n",
      "  warmup_time: 0.004536867141723633\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 18:12:47,035\tINFO tune.py:758 -- Total run time: 33.58 seconds (33.42 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best result: Result(metrics={'loss': 0.38084739446640015, '_timestamp': 1665997941, '_time_this_iter_s': 0.09299302101135254, '_training_iteration': 20, 'should_checkpoint': True, 'done': True, 'trial_id': 'c9b63_00000', 'experiment_tag': '0_lr=0.0002'}, error=None, log_dir=PosixPath('/Users/yjkim/ray_results/TorchTrainer_2022-10-17_18-12-13/TorchTrainer_c9b63_00000_0_lr=0.0002_2022-10-17_18-12-13'))\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "param_space = {\"train_loop_config\": {\"lr\": tune.loguniform(0.0001, 0.01)}}\n",
    "metric = \"loss\"\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(num_samples=5, metric=metric, mode='min')\n",
    ")\n",
    "\n",
    "# excute tuning\n",
    "result_grid = tuner.fit()\n",
    "\n",
    "# Fetch the best result\n",
    "best_result = result_grid.get_best_result()\n",
    "print(f\"best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d8ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.batch_predictor import BatchPredictor\n",
    "from ray.train.torch import TorchPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64713021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch inference\n",
    "checkpoint = best_result.checkpoint\n",
    "\n",
    "batch_predictor = BatchPredictor.from_checkpoint(\n",
    "    che\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
